{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fórmula de la Entropía\n",
    "\n",
    "$$\n",
    "H(p) = - \\sum_i^m p_i * log_2\\left| p_i \\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(p):\n",
    "    return - np.sum(p * np.log2(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fórmula del Gini (a medias)\n",
    "\n",
    "$$\n",
    "G(p) = \\sum_i^m p_i^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(p):\n",
    "    return np.sum(p**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ganancia\n",
    "\n",
    "$$\n",
    "Gain(Y, F_j) = H(Y) - \\sum_{f\\hspace{1mm}\\epsilon\\hspace{1mm} val(F)} \\frac{\\left|Y_f\\right|}{\\left|Y\\right|} * H(Y_f)\n",
    "$$\n",
    "\n",
    "Sin embargo por fines de implementación y velocidad, calculamos sólo el segúndo término de la ganancia $\\sum_{f\\hspace{1mm}\\epsilon\\hspace{1mm} val(F)} \\frac{\\left|Y_f\\right|}{\\left|Y\\right|} * H(Y_f)$, ya la entropía total la calculamos al construir el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(X, Y, feature_index):\n",
    "    gain = 0\n",
    "    ggain = 0\n",
    "    m = len(X)\n",
    "    X_col = np.asanyarray(X)[:, feature_index]\n",
    "    Y_col = np.asanyarray(Y)\n",
    "\n",
    "    values = list(Counter(X_col).keys())\n",
    "\n",
    "    for value in values:\n",
    "        ##Extraemos los índices de las filas con el valor f en F\n",
    "        indexes = np.where( X_col == value )\n",
    "        targets_for_value = Y_col[indexes]\n",
    "        \n",
    "        ##Extraemos los números de elementos por cada valor de Y\n",
    "        ##en la sub tabla con valores f en F\n",
    "        count = Counter(targets_for_value)\n",
    "        class_counts = np.asarray(list(count.values()))\n",
    "        label_values_for_value = np.asarray(list(count.keys()))\n",
    "        \n",
    "        ##Número de filas con el valor f en F\n",
    "        feature_counts = indexes[0].shape[0]\n",
    "        #feature_counts = np.sum(class_counts)\n",
    "        \n",
    "        ##Entropía y Gini\n",
    "        ##Mandamos los elementos usando el broadcasting de np\n",
    "        ##dividiendo entre el número de entradas\n",
    "        val_entropy = H(class_counts/feature_counts)\n",
    "        val_gini = G(class_counts/feature_counts)\n",
    "\n",
    "        gain += feature_counts/m * val_entropy\n",
    "        ggain += feature_counts/m * val_gini\n",
    "        \n",
    "    return gain, 1-ggain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el árbol recursivamente respetando los tres casos dentro de las condicionales.\n",
    "\n",
    "Calculamos la entropía completa al inicio de la función con la sub tabla correspondiente, y vamos restando los valores para el gain sólo si se debe entrar en la recursión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(X, Y, featureNames):\n",
    "    ## classes: Y\n",
    "    ## data: X\n",
    "    \n",
    "    m = len(X)\n",
    "    n = len(X[0])\n",
    "    \n",
    "    ##GET all target values of the actual node subset\n",
    "    newY = list(Counter(Y).keys())\n",
    "    \n",
    "    #################################\n",
    "    ##COUNT number of occurrencies of each target value\n",
    "    ##Of the subset in that node and save it in 'freq'\n",
    "    count_target_values = Counter(Y)\n",
    "    freq = np.asarray([count_target_values[t] for t in newY])\n",
    "    \n",
    "    #Calculate entropy\n",
    "    totalEntropy = H(freq/m)\n",
    "    \n",
    "    #Calculate gini\n",
    "    totalGini = G(freq/m)\n",
    "    totalGini = 1 - totalGini\n",
    "    \n",
    "    #Set default value as most repeated val\n",
    "    default = Y[np.argmax(freq)]\n",
    "    \n",
    "    ##################################\n",
    "    \n",
    "    if m == 0 or n == 0:\n",
    "        ##Rama Vacía\n",
    "        return default\n",
    "    elif len(Counter(Y)) == 1:\n",
    "        #Si sólo queda un valor de targets retornamos ese valor\n",
    "        return Y[0]\n",
    "    else:\n",
    "        ###################################\n",
    "        \n",
    "        gain = np.zeros(n)\n",
    "        ggain = np.zeros(n)\n",
    "        for feature in range(n): #n : nro de features\n",
    "            ##Cada 'feature': es un índice así que son números\n",
    "            \n",
    "            ##AQUÍ RECIÉN RESTAMOS LA PARTE DE LA SUMATORIA DEL GAIN\n",
    "            ##VALOR POR VALOR DE F A LA ENTROPÍA TOTAL.\n",
    "            g, gg = info_gain(X, Y, feature)\n",
    "            \n",
    "            ##Guardamos el gain por cada F\n",
    "            gain[feature] = totalEntropy - g\n",
    "            ggain[feature] = totalGini - gg\n",
    "            \n",
    "        ##Agarramos el índice de la mejor feature F\n",
    "        #bestFeature_index = np.argmax(gain)\n",
    "        bestFeature_index = np.argmax(ggain)\n",
    "        tree = {featureNames[bestFeature_index]: {}}\n",
    "\n",
    "        #####################################\n",
    "        \n",
    "        X_arr = np.asanyarray(X)\n",
    "        X_col = X_arr[:, bestFeature_index]\n",
    "        Y_col = np.asanyarray(Y)\n",
    "        \n",
    "        ##Agarramos,los valores que puede tomar\n",
    "        ##la mejor característica F.\n",
    "        values = list(Counter(X_col).keys())\n",
    "\n",
    "        #########################        \n",
    "        for value in values:\n",
    "            ##Índices de las filas con valor f en la feature F\n",
    "            value_indexes = np.where(X_col == value)[0]\n",
    "\n",
    "            ##Slice con todas las colúmnas menos la que hay que\n",
    "            ##eliminar porque esa se está usando\n",
    "            features_to_keep = np.arange(X_arr.shape[1])\n",
    "            features_to_keep = np.delete(features_to_keep, bestFeature_index)\n",
    "\n",
    "            X_new = X_arr[:, features_to_keep]\n",
    "            X_new = X_new[value_indexes, :]\n",
    "            \n",
    "            ##newData: Nuevo 'X' con sólo las filas con valor f,\n",
    "            ##pero eliminando la colúmna F\n",
    "            newData = X_new.tolist()\n",
    "            \n",
    "            ##Los targets correspondientes con las colúmnas con\n",
    "            ##valor f en F\n",
    "            newClasses = Y_col[value_indexes].tolist()\n",
    "            \n",
    "            ##Las columnas a quedarse, lo mismo que features_to_keep\n",
    "            ##pero con los nombres de colúmnas\n",
    "            newNames = list(np.asanyarray(featureNames)[features_to_keep])\n",
    "\n",
    "            ##Creamos el sub árbol.\n",
    "            subtree = build(newData, newClasses, newNames)\n",
    "            \n",
    "            ##Guardamos sub el árbol.\n",
    "            tree[featureNames[bestFeature_index]][value] = subtree\n",
    "            \n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('golf_dataset')\n",
    "#df = pd.read_csv('plans_dataset')\n",
    "df.replace({False: 'false', True: 'true'}, inplace=True)\n",
    "features = list(df)\n",
    "X = df[features[:-1]].values.tolist()\n",
    "Y = df[features[-1]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build(X, Y, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Outlook': {'overcast': 'yes',\n",
       "  'rainy': {'Windy': {'false': 'yes', 'true': 'no'}},\n",
       "  'sunny': {'Humidity': {'high': 'no', 'normal': 'yes'}}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, q, featureNames):\n",
    "\n",
    "    if isinstance(tree, str):\n",
    "        # Alcanzamos una hoja\n",
    "        return tree\n",
    "    else:\n",
    "        a = list(tree.keys())[0]\n",
    "        for i in range(len(featureNames)):\n",
    "            if featureNames[i]==a:\n",
    "                break\n",
    "        \n",
    "        try:\n",
    "            t = tree[a][q[i]]\n",
    "            return classify(t,q, featureNames)\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overcast', 'hot', 'high', 'false']\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "q = np.asanyarray(X)[0, :].tolist()\n",
    "print(q)\n",
    "print( classify(tree, q, features) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['overcast', 'hot', 'high', 'false'],\n",
       " ['overcast', 'cool', 'normal', 'true'],\n",
       " ['overcast', 'mild', 'high', 'true'],\n",
       " ['overcast', 'hot', 'normal', 'false'],\n",
       " ['rainy', 'mild', 'high', 'false'],\n",
       " ['rainy', 'cool', 'normal', 'false'],\n",
       " ['rainy', 'cool', 'normal', 'true'],\n",
       " ['rainy', 'mild', 'normal', 'false'],\n",
       " ['rainy', 'mild', 'high', 'true'],\n",
       " ['sunny', 'hot', 'high', 'false'],\n",
       " ['sunny', 'hot', 'high', 'true'],\n",
       " ['sunny', 'mild', 'high', 'false'],\n",
       " ['sunny', 'cool', 'normal', 'false'],\n",
       " ['sunny', 'mild', 'normal', 'true']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Outlook', 'Temperature', 'Humidity', 'Windy', 'Play']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['overcast', 'hot', 'high', 'false', 'yes'],\n",
       "       ['overcast', 'cool', 'normal', 'true', 'yes'],\n",
       "       ['overcast', 'mild', 'high', 'true', 'yes'],\n",
       "       ['overcast', 'hot', 'normal', 'false', 'yes'],\n",
       "       ['rainy', 'mild', 'high', 'false', 'yes'],\n",
       "       ['rainy', 'cool', 'normal', 'false', 'yes'],\n",
       "       ['rainy', 'cool', 'normal', 'true', 'no'],\n",
       "       ['rainy', 'mild', 'normal', 'false', 'yes'],\n",
       "       ['rainy', 'mild', 'high', 'true', 'no'],\n",
       "       ['sunny', 'hot', 'high', 'false', 'no'],\n",
       "       ['sunny', 'hot', 'high', 'true', 'no'],\n",
       "       ['sunny', 'mild', 'high', 'false', 'no'],\n",
       "       ['sunny', 'cool', 'normal', 'false', 'yes'],\n",
       "       ['sunny', 'mild', 'normal', 'true', 'yes']], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_arr = df.values.copy()\n",
    "sk_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 2, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 2, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 2, 1, 0, 0],\n",
       "       [1, 2, 0, 1, 1],\n",
       "       [2, 0, 0, 0, 1],\n",
       "       [2, 0, 0, 1, 1],\n",
       "       [2, 2, 0, 0, 1],\n",
       "       [2, 1, 1, 0, 0],\n",
       "       [2, 2, 1, 1, 0]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_arr = df.values\n",
    "for col in range(X_arr.shape[1]):\n",
    "    F = list(Counter(X_arr[:, col].tolist()).keys())\n",
    "    for val, f in enumerate(F):\n",
    "        #print(i, f)\n",
    "        indexes = np.where(sk_arr == f)\n",
    "        sk_arr[indexes] = val\n",
    "sk_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "(14, 3)\n",
      "_________________________________________________\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "(14, 3)\n",
      "_________________________________________________\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "(14, 2)\n",
      "_________________________________________________\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "(14, 2)\n",
      "_________________________________________________\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "(14, 2)\n",
      "_________________________________________________\n",
      "FINAL ARRAY: (14, 12)\n",
      "[[1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0.]]\n",
      "------------------------------\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "------------------------------\n",
      "[[1. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "X_list = []\n",
    "for i in range(sk_arr.shape[1]):\n",
    "    col = sk_arr[:, i].reshape(sk_arr.shape[0], 1)\n",
    "    print(col)\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(col)\n",
    "    encoded = enc.transform(col).toarray()\n",
    "    print()\n",
    "    print(encoded)\n",
    "    print(encoded.shape)\n",
    "    X_list.append(encoded)\n",
    "    print('_________________________________________________')\n",
    "    \n",
    "encoded_X = np.hstack(X_list)\n",
    "print('FINAL ARRAY:', encoded_X.shape)\n",
    "print(encoded_X)\n",
    "print('------------------------------')\n",
    "encoded_Y = encoded_X[:, -2:]\n",
    "print(encoded_Y)\n",
    "print('------------------------------')\n",
    "encoded_X = encoded_X[:, :-2]\n",
    "print(encoded_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(encoded_X, encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(dtree, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a695b57043d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, prog)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             self.__setattr__(\n\u001b[1;32m   1796\u001b[0m                 \u001b[0;34m'create_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m                 \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m             )\n\u001b[1;32m   1799\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[0;32m-> 1960\u001b[0;31m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[1;32m   1961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
